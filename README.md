Breast cancer early detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10z6veKCwPjMuIII3WOj0gwBg_3O0dknP

!pip install numpy
!pip install pandas
!pip install matplotlib
!pip install seaborn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/data.csv')

df.head()

from google.colab import files
upload = files.upload()

df_1 = pd.read_csv('/content/data (1).csv')

df_1.head()

! pip  install kaggle
! mkdir ~/ .kaggle
! cp kaggle.json ~/.kaggle
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download uciml/breast-cancer-wisconsin-data

! unzip breast-cancer-wisconsin-data.zip

df = pd.read_csv("/content/data.csv")

df.head()

df.shape

df.info()

df.isnull().sum()

from google.colab import drive
drive.mount('/content/drive')

df = df.dropna(axis=1)

df.shape

df.dtypes

df['diagnosis'].value_counts()

sns.countplot(df['diagnosis'], label = "count")

from sklearn.preprocessing import LabelEncoder
labelencoder_Y = LabelEncoder()

df.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values)

df.iloc[:,1].values

sns.pairplot(df.iloc[:,1:7], hue='diagnosis')

df.iloc[:,1:11].corr()

plt.figure(figsize = (10, 10))
sns.heatmap(df.iloc[:,1:11].corr(), cmap="YlGnBu", annot=True, fmt= '.0%')

X = df.iloc[:,2:31].values
Y = df.iloc[:,1].values

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

X_train

def models(X_train, Y_train):
  from sklearn.linear_model import LogisticRegression
  log = LogisticRegression(random_state = 0)
  log.fit(X_train, Y_train)

  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion= "entropy", random_state= 0)
  tree.fit(X_train, Y_train)

  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators= 10, criterion= "entropy", random_state= 0)
  forest.fit(X_train, Y_train)

  #print the accuracy of each model on the training dataset
  print("The accuracy of Logistic Regression: ",log.score(X_train, Y_train))
  print("The accuracy of Decision Tree: ",tree.score(X_train, Y_train))
  print("The accuracy of Random Regression: ",forest.score(X_train, Y_train))

  return log, tree, forest

model = models(X_train, Y_train)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y_test, model[0].predict(X_test))
tp = cm[0][0]
tn = cm[1][1]
fn = cm[1][0]
fp = cm[0][1]
print(cm)
print("Accuracy: ",(tp+tn)/(tp+tn+fp+fn))

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

for i in range(len(model)):
  print('Model: ',i)
  print(classification_report(Y_test, model[i].predict(X_test)))
  print(accuracy_score(Y_test, model[i].predict(X_test)))
  print()

#prediction
pred = model[2].predict(X_test)
print('Our model prediction: ')
print(pred)
print()
print('Actual prediction: ')
print(Y_test)
